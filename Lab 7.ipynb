{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating random sets of data with 50, 60, 70, 80, 90, and 100 percent zeros. Packing them with np.packbits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pack = np.packbits\n",
    "\n",
    "z50 = pack(np.random.choice([0, 1], size=1024, replace=True, p=[0.5, 0.5]))\n",
    "z60 = pack(np.random.choice([0, 1], size=1024, replace=True, p=[.6,.4]))\n",
    "z70 = pack(np.random.choice([0, 1], size=1024, replace=True, p=[.7,.3]))\n",
    "z80 = pack(np.random.choice([0, 1], size=1024, replace=True, p=[.8,.2]))\n",
    "z90 = pack(np.random.choice([0, 1], size=1024, replace=True, p=[.9,.1]))\n",
    "z100 = pack(np.random.choice([0, 1], size=1024, replace=True, p=[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing first file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('z50', 'wb').write(z50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing rest of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('z60', 'wb').write(z60)\n",
    "open('z70', 'wb').write(z70)\n",
    "open('z80', 'wb').write(z80)\n",
    "open('z90', 'wb').write(z90)\n",
    "open('z100', 'wb').write(z100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating random arrays of DNA and protein code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna = np.random.choice(['a', 't', 'g', 'c'], size=100000000, replace=True, p=[.25, .25, .25, .25])\n",
    "protein = np.random.choice(['G', 'P', 'A', 'V', 'L', 'I', 'M', 'C', 'F', 'Y', 'W', 'H', 'K', 'R', 'Q', 'N', 'E', 'D', 'S', 'T'], size=100000000, replace=True, p=[.05, .05, .05, .05,.05, .05, .05, .05,.05, .05, .05, .05,.05, .05, .05, .05,.05, .05, .05, .05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn arrays into strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna = ''.join(dna)\n",
    "protein = ''.join(protein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write those strings to fasta files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('dna.fa', 'w').write(dna)\n",
    "open('protein.fa', 'w').write(protein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the screenshots of our terminal commands.\n",
    "![gzip](https://bioe131.com/user/be131-41/files/gzip/gzip%20terminal.PNG \"gzip terminal\")\n",
    "![bzip2](https://bioe131.com/user/be131-41/files/bzip2/bzip2%20terminal.PNG \"bzip2 terminal\")\n",
    "![pbzip2](https://bioe131.com/user/be131-41/files/pbzip2/pbzip2%20terminal.PNG \"pbzip2 terminal\")\n",
    "![ArithmeticCompress](https://bioe131.com/user/be131-41/files/ArithmeticCompress/ArithmeticCompress%20terminal.PNG \"ArithmeticCompress terminal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|sample name|in size|gzip size|bzip2 size|pbzip2 size|ArithmeticCompress size|gzip time|bzip2 time|pbzip2 time|ArithmeticCompress time|\n",
    "|------|------|------|------|------|------|------|------|------|------|\n",
    "|z50|128 B|155 B| 207 B|207 B|1.13 kB|.002s|.003s|.005s|.012s|\n",
    "|z60|128 B|155 B| 207 B|207 B|1.13 kB|.002s|.003s|.005s|.005s|\n",
    "|z70|128 B|155 B| 203 B|203 B|1.12 kB|.002s|.003s|.005s|.005s|\n",
    "|z80|128 B|155 B| 194 B|194 B|1.11 kB|.002s|.002s|.004s|.005s|\n",
    "|z90|128 B|124 B| 136 B|136 B|1.08 kB|.002s|.002s|.005s|.006s|\n",
    "|z100|128 B|29 B| 39 B|39 B|1.02 kB|.002s|.002s|.005s|.005s|\n",
    "|dna.fa|100 MB|29.2 MB| 27.3 MB|27.3 MB|25 MB|12.144s|9.496s|.684s|21.340s|\n",
    "|protein.fa|100 MB|60.6 MB| 55.3 MB|55.3 MB|54 MB|4.286s|10.024s|.824s|28.542s|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions to answer:\n",
    "###### Which algorithm achieves the best level of compression on each file type?\n",
    "The smallest outsize for z50-z100 was the file compressed with gzip. The smallest outsize for dna.fa and protein.fa was achieved with ArithmeticCompress.\n",
    "###### Which algorithm is the fastest?\n",
    "On average, gzip was definitely the fastest.\n",
    "###### What is the difference between bzip2 and pbzip2?\n",
    "The time for bzip2 was .002-.003 seconds faster than for pbzip2 for files z50-z100. However, pbzip2 was more than 10x faster than bzip2 for the two larger files, dna.fa and protein.fa.\n",
    "###### Do you expect one to be faster and why?\n",
    "pbzip2 is a parallel implementation of the bzip2 block-sorting file compressor that uses pthreads and achieves near-linear speedup on SMP machines. The documentation also says that you should be able to compress files larger than 4GB with pbzip2. Therefore it makes sense that pbzip2 begins to become faster as the file sizes become more similar to practical file sizes (100MB for dna.fa and protein.fa vs 128B for z50-z100)\n",
    "###### How does the level of compression change as the percentage of zeros increases?\n",
    "The compressed files become a lot smaller as there are more zeros.\n",
    "###### Why does this happen?\n",
    "This is because the information content of each 0 is much lower than the information content of each 1.\n",
    "###### What is the minimum number of bits required to store a single DNA base?\n",
    "log2(4) bits per nucleotide = 2 bits per nucleotide.\n",
    "###### What is the minimum number of bits required to store an amino acid letter?\n",
    "log2(20) bits per amino acid = 4.32 bits per amino acid\n",
    "###### In your tests, how many bits did gzip and bzip2 actually require to store your random DNA and protein sequences?\n",
    "For dna.fa, gzip required 29.2MB and bzip2 required 27.3MB. For protein.fa, gzip required 60.6MB and bzip2 required 55.3MB.\n",
    "###### Are gzip and bzip2 performing well on DNA and proteins?\n",
    "Each of our dna and protein files had 100,000,000 elements in the sequence. 100,000,000 * 2 bits = 25MB. Gzip is 4.2MB from that ideal and bzip2 is only 2.3MB away, so I would say good performance. 100,000,000 * 4.32 bits = 54.024MB. Gzip is 6.576MB away and bzip2 is 1.276MB away from the ideal Shannon information content of the sequences. Both are performing well but bzip2 is performing better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move on to compressing real genetic data. \n",
    "###### A priori, doyou expect to achieve better or worse compression here than random data? Why?\n",
    "We expect better compression than with random data, because there are more likely to be stretches of one nucleotide or repetitive stretches of one nucleotide motif than in a randomly generated sequence of four letters unrelated by evolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compressed the gp120.fasta file downloaded from [NCBI](https://www.ncbi.nlm.nih.gov/nuccore/?term=HIV%20Envelope%20Protein%20gp120).\n",
    "\n",
    "![gp120 terminal](https://bioe131.com/user/be131-41/files/gp120%20terminal.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### How does the compression ratio of this file compare to random data?\n",
    "Interestingly, the original gp120.fasta file seems to have the smallest size when comparing it with all the compressed filed.\n",
    "\n",
    "|original|gzip|bzip2|pbzip2|\n",
    "|--------|----|-----|------|\n",
    "|1.02 kB|2.67 kB|3.54 kB|3.54 kB|\n",
    "\n",
    "Thus, the compression ratio shows that for this file, the compression was kind of useless, as it was for our files z50-z90. The compression ratio for our 100 MB files showed that compression to be much more effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final question\n",
    "## Estimating compression of 1000 terabytes\n",
    "Let’s make some assumptions about the contents of the data at your biotech company. Most of the data, say 80%, is re-sequencing of genomes and plasmids that are very similar to each other. Another 10% might be protein sequences, and the last 10% are binary microscope images which we’ll assume follow the worst-case scenario of being completely random. Given the benchmarking data you obtained in this lab, which algorithm do you propose to use for each type of data? Provide an estimate for the fraction of space you can save using your compression scheme. How much of a bonus do you anticipate receiving this year? (They process 1 TB of data per day and a 1% reduction in data storage translates into a $500 savings per day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
